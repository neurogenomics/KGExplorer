% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/0docs.R, R/get_alphamissense.R,
%   R/get_clinvar.R, R/get_data_package.R, R/get_definitions.R, R/get_gencc.R,
%   R/get_gene_lengths.R, R/get_genes_disease.R, R/get_graph_colnames.R,
%   R/get_medgen_maps.R, R/get_metadata_omim.R, R/get_metadata_orphanet.R,
%   R/get_monarch.R, R/get_monarch_files.R, R/get_monarch_kg.R,
%   R/get_monarch_models.R, R/get_mondo_maps.R, R/get_mondo_maps_files.R,
%   R/get_ols_options.R, R/get_ontology.R, R/get_ontology_dict.R,
%   R/get_ontology_levels.R, R/get_pli.R, R/get_prevalence.R, R/get_ttd.R,
%   R/get_upheno.R, R/get_version.R
\name{get_}
\alias{get_}
\alias{get_alphamissense}
\alias{get_clinvar}
\alias{get_data_package}
\alias{get_definitions}
\alias{get_gencc}
\alias{get_gene_lengths}
\alias{get_genes_disease}
\alias{get_graph_colnames}
\alias{get_medgen_maps}
\alias{get_metadata_omim}
\alias{get_metadata_orphanet}
\alias{get_monarch}
\alias{get_monarch_files}
\alias{get_monarch_kg}
\alias{get_monarch_models}
\alias{get_mondo_maps}
\alias{get_mondo_maps_files}
\alias{get_ols_options}
\alias{get_ontology}
\alias{get_ontology_dict}
\alias{get_ontology_levels}
\alias{get_pli}
\alias{get_prevalence}
\alias{get_ttd}
\alias{get_upheno}
\alias{get_version}
\title{Get functions}
\source{
\href{https://ftp.ncbi.nlm.nih.gov/pub/clinvar/}{ClinVar server}

\href{https://ftp.ncbi.nlm.nih.gov/pub/clinvar/README.txt}{
ClinVar server README}

\href{https://github.com/charlieccarey/monarchr}{
monarchr R package (abandoned project?)}

\href{https://pubmed.ncbi.nlm.nih.gov/37707514/}{BioThings Explorer}

\href{https://rdrr.io/github/frequena/rbiolink/}{rbiolink}

\href{https://github.com/biolink/kgx}{KGX}
}
\usage{
get_alphamissense(
  types = c("canonical", "non_canonical", "merged"),
  agg_fun = mean,
  save_dir = cache_dir(),
  force_new = FALSE
)

get_clinvar(as_granges = FALSE, annotate = FALSE)

get_data_package(name, package = "KGExplorer")

get_definitions(ont, from = "id", to = "definition")

get_gencc(
  agg_by = c("disease_id", "gene_symbol"),
  dict = c(Definitive = 6, Strong = 5, Moderate = 4, Supportive = 3, Limited = 2,
    `Disputed Evidence` = 1, `Refuted Evidence` = 0, `No Known Disease Relationship` = 0),
  save_dir = cache_dir(),
  force_new = FALSE
)

get_gene_lengths(genes, keep_chr = c(seq(22), "X", "Y"), ensembl_version = 75)

get_genes_disease(
  maps = list(c("gene", "disease")),
  run_map_mondo = FALSE,
  to = c("OMIM", "Orphanet", "DECIPHER"),
  ...
)

get_graph_colnames(g, what = c("nodes", "edges"))

get_medgen_maps()

get_metadata_omim(save_dir = cache_dir())

get_metadata_orphanet(save_dir = cache_dir())

get_monarch(
  queries = NULL,
  maps = NULL,
  domain = "https://data.monarchinitiative.org",
  subdir = "latest/tsv/all_associations/",
  rbind = FALSE,
  save_dir = cache_dir()
)

get_monarch_files(
  maps = NULL,
  queries = NULL,
  domain = "https://data.monarchinitiative.org",
  subdir = "latest/tsv/all_associations/",
  omit = c("...", "md5sums", "index.html")
)

get_monarch_kg(as_graph = TRUE, save_dir = cache_dir(), force_new = FALSE, ...)

get_monarch_models(
  maps = list(m2d = c("model", "disease")),
  filters = list(disease = NULL, gene = NULL, variant = NULL),
  input_col = "object",
  to = NULL,
  map_orthologs = TRUE,
  as_graph = FALSE,
  ...
)

get_mondo_maps(
  map_types = c("default", "broadmatch", "closematch", "exactmatch", "hasdbxref",
    "narrowmatch", "relatedmatch"),
  map_to = NULL,
  map_type_order = c("default", "exactmatch", "closematch", "narrowmatch", "broadmatch",
    "relatedmatch", "hasdbxref"),
  top_n = NULL,
  top_by = c("subject", "object"),
  save_dir = cache_dir()
)

get_mondo_maps_files(map_types, map_to, save_dir)

get_ols_options(ol = rols::Ontologies())

get_ontology(
  name = c("mondo", "hp", "upheno", "uberon", "cl"),
  method = c("rols", "github"),
  terms = NULL,
  add_metadata = TRUE,
  add_ancestors = 2,
  add_n_edges = TRUE,
  add_ontology_levels = TRUE,
  save_dir = cache_dir(),
  force_new = FALSE,
  ...
)

get_ontology_dict(ont, from = "id", to = "name", include_self = FALSE)

get_ontology_levels(
  ont,
  terms = NULL,
  remove_terms = TRUE,
  method = c("depth", "height"),
  absolute = TRUE,
  reverse = FALSE
)

get_pli(agg_fun = mean, save_dir = cache_dir(), force_new = FALSE)

get_prevalence(
  method = c("orphanet", "oard"),
  agg_by = c("mondo_id", "id", "Name"),
  include_mondo = TRUE,
  ...
)

get_ttd(save_dir = cache_dir(), run_map_genes = TRUE)

get_upheno(file = c("ontology", "bestmatches", "upheno_mapping"))

get_version(obj, return_version = FALSE, verbose = TRUE)
}
\arguments{
\item{types}{A character vector of types to return.}

\item{agg_fun}{A function to aggregate multiple transcripts per gene.}

\item{save_dir}{Directory to save a file to.}

\item{force_new}{If TRUE, force a new download.}

\item{as_granges}{Return the object as a \link[GenomicRanges]{GRanges}.}

\item{annotate}{Add variant annotations with \link{map_variants}.}

\item{name}{\itemize{
\item{<...>}{Any ontology name from \link{get_ols_options}}
\item{"mondo"}{
Import the \href{https://mondo.monarchinitiative.org/}{Mondo} ontology.
\href{https://github.com/monarch-initiative/mondo/release}{
GitHub.}}.
\item{"hpo"}{
Import the \href{https://hpo.jax.org/app/}{Human Phenotype Ontology}.
\href{https://github.com/obophenotype/human-phenotype-ontology/release}{
GitHub.}}
}}

\item{package}{
    a character vector giving the package(s) to look
    in for data sets, or \code{NULL}.

    By default, all packages in the search path are used, then
    the \file{data} subdirectory (if present) of the current working
    directory.
  }

\item{ont}{An ontology of class \link[simona]{ontology_DAG}.}

\item{from}{The designated from column in from-to mapping or relations.}

\item{to}{A character string specifying the format to convert to.}

\item{agg_by}{Column names to aggregate results by.}

\item{dict}{A named vector of evidence score mappings.
See \href{https://thegencc.org/faq.html#validity-termsdelphi-survey}{here}
for more information.}

\item{genes}{A character vector of gene symbols}

\item{keep_chr}{Which chromosomes to keep.}

\item{ensembl_version}{Which Ensembl database version to use.}

\item{maps}{A list of paired to/from types to filter Monarch association 
files by. For example, \code{list(c("gene","disease"))} will return any 
 files that contains gene-disease associations.
Passes to \link{get_monarch_files}.}

\item{run_map_mondo}{Run \link{map_mondo} to map MONDO IDs to disease IDs.}

\item{...}{
  Arguments passed on to \code{\link[=link_monarch]{link_monarch}}, \code{\link[data.table:fread]{data.table::fread}}, \code{\link[data.table:fread]{data.table::fread}}, \code{\link[=get_ontology_github]{get_ontology_github}}
  \describe{
    \item{\code{node_filters}}{A named list of filters to apply to the node data. 
Names should be name of the metadata column, and values should be a vector of 
valid options. For example, \code{list("type" = c("gene","variant"))} will
return any rows where the "type" column contains either "gene" or "variant".}
    \item{\code{input}}{ A single character string. The value is inspected and deferred to either \code{file=} (if no \\n present), \code{text=} (if at least one \\n is present) or \code{cmd=} (if no \\n is present, at least one space is present, and it isn't a file name). Exactly one of \code{input=}, \code{file=}, \code{text=}, or \code{cmd=} should be used in the same call. }
    \item{\code{text}}{ The input data itself as a character vector of one or more lines, for example as returned by \code{readLines()}. }
    \item{\code{cmd}}{ A shell command that pre-processes the file; e.g. \code{fread(cmd=paste("grep",word,"filename"))}. See Details. }
    \item{\code{sep}}{ The separator between columns. Defaults to the character in the set \code{[,\\t |;:]} that separates the sample of rows into the most number of lines with the same number of fields. Use \code{NULL} or \code{""} to specify no separator; i.e. each line a single character column like \code{base::readLines} does.}
    \item{\code{sep2}}{ The separator \emph{within} columns. A \code{list} column will be returned where each cell is a vector of values. This is much faster using less working memory than \code{strsplit} afterwards or similar techniques. For each column \code{sep2} can be different and is the first character in the same set above [\code{,\\t |;}], other than \code{sep}, that exists inside each field outside quoted regions in the sample. NB: \code{sep2} is not yet implemented. }
    \item{\code{nrows}}{ The maximum number of rows to read. Unlike \code{read.table}, you do not need to set this to an estimate of the number of rows in the file for better speed because that is already automatically determined by \code{fread} almost instantly using the large sample of lines. \code{nrows=0} returns the column names and typed empty columns determined by the large sample; useful for a dry run of a large file or to quickly check format consistency of a set of files before starting to read any of them. }
    \item{\code{header}}{ Does the first data line contain column names? Defaults according to whether every non-empty field on the first data line is type character. If so, or TRUE is supplied, any empty column names are given a default name. }
    \item{\code{na.strings}}{ A character vector of strings which are to be interpreted as \code{NA} values. By default, \code{",,"} for columns of all types, including type \code{character} is read as \code{NA} for consistency. \code{,"",} is unambiguous and read as an empty string. To read \code{,NA,} as \code{NA}, set \code{na.strings="NA"}. To read \code{,,} as blank string \code{""}, set \code{na.strings=NULL}. When they occur in the file, the strings in \code{na.strings} should not appear quoted since that is how the string literal \code{,"NA",} is distinguished from \code{,NA,}, for example, when \code{na.strings="NA"}. }
    \item{\code{stringsAsFactors}}{ Convert all or some character columns to factors? Acceptable inputs are \code{TRUE}, \code{FALSE}, or a decimal value between 0.0 and 1.0. For \code{stringsAsFactors = FALSE}, all string columns are stored as \code{character} vs. all stored as \code{factor} when \code{TRUE}. When \code{stringsAsFactors = p} for \code{0 <= p <= 1}, string columns \code{col} are stored as \code{factor} if \code{uniqueN(col)/nrow < p}. 
  }
    \item{\code{skip}}{ If 0 (default) start on the first line and from there finds the first row with a consistent number of columns. This automatically avoids irregular header information before the column names row. \code{skip>0} means ignore the first \code{skip} rows manually. \code{skip="string"} searches for \code{"string"} in the file (e.g. a substring of the column names row) and starts on that line (inspired by read.xls in package gdata). }
    \item{\code{select}}{ A vector of column names or numbers to keep, drop the rest. \code{select} may specify types too in the same way as \code{colClasses}; i.e., a vector of \code{colname=type} pairs, or a \code{list} of \code{type=col(s)} pairs. In all forms of \code{select}, the order that the columns are specified determines the order of the columns in the result. }
    \item{\code{drop}}{ Vector of column names or numbers to drop, keep the rest. }
    \item{\code{colClasses}}{ As in \code{\link[utils:read.table]{utils::read.csv}}; i.e., an unnamed vector of types corresponding to the columns in the file, or a named vector specifying types for a subset of the columns by name. The default, \code{NULL} means types are inferred from the data in the file. Further, \code{data.table} supports a named \code{list} of vectors of column names \emph{or numbers} where the \code{list} names are the class names; see examples. The \code{list} form makes it easier to set a batch of columns to be a particular class. When column numbers are used in the \code{list} form, they refer to the column number in the file not the column number after \code{select} or \code{drop} has been applied.
    If type coercion results in an error, introduces \code{NA}s, or would result in loss of accuracy, the coercion attempt is aborted for that column with warning and the column's type is left unchanged. If you really desire data loss (e.g. reading \code{3.14} as \code{integer}) you have to truncate such columns afterwards yourself explicitly so that this is clear to future readers of your code.
  }
    \item{\code{integer64}}{ "integer64" (default) reads columns detected as containing integers larger than 2^31 as type \code{bit64::integer64}. Alternatively, \code{"double"|"numeric"} reads as \code{utils::read.csv} does; i.e., possibly with loss of precision and if so silently. Or, "character". }
    \item{\code{dec}}{ The decimal separator as in \code{utils::read.csv}. If not "." (default) then usually ",". See details. }
    \item{\code{col.names}}{ A vector of optional names for the variables (columns). The default is to use the header column if present or detected, or if not "V" followed by the column number. This is applied after \code{check.names} and before \code{key} and \code{index}. }
    \item{\code{check.names}}{default is \code{FALSE}. If \code{TRUE} then the names of the variables in the \code{data.table} are checked to ensure that they are syntactically valid variable names. If necessary they are adjusted (by \code{\link{make.names}}) so that they are, and also to ensure that there are no duplicates.}
    \item{\code{encoding}}{ default is \code{"unknown"}. Other possible options are \code{"UTF-8"} and \code{"Latin-1"}.  Note: it is not used to re-encode the input, rather enables handling of encoded strings in their native encoding. }
    \item{\code{quote}}{ By default (\code{"\\""}), if a field starts with a double quote, \code{fread} handles embedded quotes robustly as explained under \code{Details}. If it fails, then another attempt is made to read the field \emph{as is}, i.e., as if quotes are disabled. By setting \code{quote=""}, the field is always read as if quotes are disabled. It is not expected to ever need to pass anything other than \\"\\" to quote; i.e., to turn it off. }
    \item{\code{strip.white}}{ default is \code{TRUE}. Strips leading and trailing whitespaces of unquoted fields. If \code{FALSE}, only header trailing spaces are removed. }
    \item{\code{fill}}{logical (default is \code{FALSE}). If \code{TRUE} then in case the rows have unequal length, blank fields are implicitly filled.}
    \item{\code{blank.lines.skip}}{\code{logical}, default is \code{FALSE}. If \code{TRUE} blank lines in the input are ignored.}
    \item{\code{key}}{Character vector of one or more column names which is passed to \code{\link[data.table]{setkey}}. It may be a single comma separated string such as \code{key="x,y,z"}, or a vector of names such as \code{key=c("x","y","z")}. Only valid when argument \code{data.table=TRUE}. Where applicable, this should refer to column names given in \code{col.names}. }
    \item{\code{index}}{ Character vector or list of character vectors of one or more column names which is passed to \code{\link[data.table]{setindexv}}. As with \code{key}, comma-separated notation like \code{index="x,y,z"} is accepted for convenience. Only valid when argument \code{data.table=TRUE}. Where applicable, this should refer to column names given in \code{col.names}. }
    \item{\code{showProgress}}{ \code{TRUE} displays progress on the console if the ETA is greater than 3 seconds. It is produced in fread's C code where the very nice (but R level) txtProgressBar and tkProgressBar are not easily available. }
    \item{\code{data.table}}{ TRUE returns a \code{data.table}. FALSE returns a \code{data.frame}. The default for this argument can be changed with \code{options(datatable.fread.datatable=FALSE)}.}
    \item{\code{nThread}}{The number of threads to use. Experiment to see what works best for your data on your hardware.}
    \item{\code{logical01}}{If TRUE a column containing only 0s and 1s will be read as logical, otherwise as integer.}
    \item{\code{keepLeadingZeros}}{If TRUE a column containing numeric data with leading zeros will be read as character, otherwise leading zeros will be removed and converted to numeric.}
    \item{\code{yaml}}{ If \code{TRUE}, \code{fread} will attempt to parse (using \code{\link[yaml]{yaml.load}}) the top of the input as YAML, and further to glean parameters relevant to improving the performance of \code{fread} on the data itself. The entire YAML section is returned as parsed into a \code{list} in the \code{yaml_metadata} attribute. See \code{Details}. }
    \item{\code{autostart}}{ Deprecated and ignored with warning. Please use \code{skip} instead. }
    \item{\code{tmpdir}}{ Directory to use as the \code{tmpdir} argument for any \code{tempfile} calls, e.g. when the input is a URL or a shell command. The default is \code{tempdir()} which can be controlled by setting \code{TMPDIR} before starting the R session; see \code{\link[base:tempfile]{base::tempdir}}. }
    \item{\code{tz}}{ Relevant to datetime values which have no Z or UTC-offset at the end, i.e. \emph{unmarked} datetime, as written by \code{\link[utils:write.table]{utils::write.csv}}. The default \code{tz="UTC"} reads unmarked datetime as UTC POSIXct efficiently. \code{tz=""} reads unmarked datetime as type character (slowly) so that \code{as.POSIXct} can interpret (slowly) the character datetimes in local timezone; e.g. by using \code{"POSIXct"} in \code{colClasses=}. Note that \code{fwrite()} by default writes datetime in UTC including the final Z and therefore \code{fwrite}'s output will be read by \code{fread} consistently and quickly without needing to use \code{tz=} or \code{colClasses=}. If the \code{TZ} environment variable is set to \code{"UTC"} (or \code{""} on non-Windows where unset vs `""` is significant) then the R session's timezone is already UTC and \code{tz=""} will result in unmarked datetimes being read as UTC POSIXct. For more information, please see the news items from v1.13.0 and v1.14.0. }
    \item{\code{filetype}}{File type to search for.}
    \item{\code{repo}}{Repository name in format "owner/repo". Defaults to \code{guess_repo()}.}
    \item{\code{tag}}{tag for the GitHub release to which this data should be attached.}
  }}

\item{g}{ggnetwork object 
(or an igraph/tbl_graph to be converted to ggnetwork format).}

\item{what}{What should get activated? Possible values are \code{nodes} or
\code{edges}.}

\item{queries}{A list of free-form substring queries to filter files by 
(using any column in the metadata). 
For example, \code{list("gene_disease","variant_disease")} will return any 
 files that contain either of the substrings 
 "gene_disease" or "variant_disease".
Passes to \link{get_monarch_files}.}

\item{domain}{Web domain to search for Monarch files.}

\item{subdir}{Subdirectory path to search for Monarch files within
\code{domain}.}

\item{rbind}{If \code{TRUE}, rbinds all \link[data.table]{data.table}s 
together. Otherwise, returns a named list of separated 
\link[data.table]{data.table}s.}

\item{omit}{Files to omit from results.}

\item{as_graph}{Return the object as a \link[tidygraph]{tbl_graph}.}

\item{filters}{A named list, where each element in the list is the name of 
a column in the data, and the vector within each element represents the 
values to include in the final data.}

\item{input_col}{Column containing IDs.}

\item{map_orthologs}{Add gene-level data.}

\item{map_types}{Mapping types to include.}

\item{map_to}{Mapping outputs to include
(from Mondo IDs to another database's IDs).}

\item{map_type_order}{The order in which \code{map_types} will be prioritised
when filtering the \code{top_n} rows by groupings.}

\item{top_n}{Top number of mappings to return per \code{top_by} grouping.
Set to \code{NULL} to skip this step.}

\item{top_by}{Grouping columns when selecting \code{top_n} rows per grouping.
Can be a character vector of one or more column names.}

\item{ol}{An \link[rols]{Ontologies} object.}

\item{method}{Compute ontology levels using:
\itemize{
 \item{"height" (default)} \link[simona]{dag_height}.
 \item{"depth"} \link[simona]{dag_depth}.
}}

\item{terms}{Term IDs to include. Can alternatively be an integer, 
which will be used to randomly sample N terms from the data.}

\item{add_metadata}{Add metadata to the resulting ontology object.}

\item{add_ancestors}{Add ancestors for each term.}

\item{add_n_edges}{Add the number of edges (connections) for each term.}

\item{add_ontology_levels}{Add the ontology level for each term.}

\item{include_self}{For \code{dag_offspring()} and \code{dag_ancestors()}, this controls whether to also include the query term itself.}

\item{remove_terms}{Character vector of term IDs to exclude.}

\item{absolute}{Make the levels absolute in the sense that they consider
the entire ontology (\code{TRUE}).
Otherwise, levels will be relative to only the terms that are in
 the provided subset of \code{terms} AND are directly adjacent (connected)
 to a given cluster of terms (\code{FALSE}).}

\item{reverse}{If \code{TRUE}, ontology
level numbers with be revered such that the level of the parent terms
are larger than the child terms.}

\item{include_mondo}{Include MONDO IDs in the output.}

\item{run_map_genes}{Map genes to standardised HGNC symbols using 
\link[orthogene]{map_genes}.}

\item{file}{Can be one of the following:
\itemize{
\item{"ontology"}{Creates an \link[simona]{ontology_DAG} R object by
 importing the OBO file directly from the official
 \href{https://github.com/obophenotype/upheno}{uPheno GitHub repository}.}
\item{"bestmatches"}{Returns a merged table with the best matches between
 human and non-human homologous phenotypes (from multiple species).
 Distributed by the official
 \href{https://github.com/obophenotype/upheno/tree/master/mappings}{
 uPheno GitHub repository}.}
\item{"upheno_mapping"}{Return a merged table with matches between human
and non-human homologous phenotypes (from multiple species).
Distributed by the
 \href{https://data.monarchinitiative.org/upheno2/current/upheno-release/all/index.html}{
 Monarch Initiative server}.}
}}

\item{obj}{An object.}

\item{return_version}{Return the version as a character string.}

\item{verbose}{Print messages.}
}
\value{
Data.

A named list of data.tables of AlphaMissense predictions.

\link[data.table]{data.table} with columns:
\itemize{
\item{"disease_id": }{Disease ID.}
\item{"gene_symbol": }{Gene symbol.}
\item{"evidence_score": }{Evidence score.}
}

data.table

\link[data.table]{data.table}

\link[data.table]{data.table} of mappings.

\link[simona]{ontology_DAG}

A named vector of relative ontology level,
where names are ontology term IDs and
value is relative ontology level.

\link[simona]{ontology_DAG} or \link[data.table]{data.table}.

Data object release version a character string.
}
\description{
Functions to get data resources.
}
\section{Functions}{
\itemize{
\item \code{get_alphamissense()}: get_
Get AlphaMissense predictions

Get gene-level
\href{https://console.cloud.google.com/storage/browser/dm_alphamissense}{
AlphaMissense} predictions for all canonical and non-canonical
protein-coding gene transcripts.

\item \code{get_clinvar()}: get_
Get ClinVar variant data

ClinSigSimple          integer, 0 = no current value of Likely pathogenic; Pathogenic; Likely pathogenic, low penetrance;
Pathogenic, low penetrance; Likely risk allele; or Risk allele
1 = at least one current record submitted with an interpretation of Likely pathogenic; Pathogenic;
Likely pathogenic, low penetrance; Pathogenic, low penetrance; Likely risk allele; 
or Risk allele (independent of whether that record includes assertion criteria and evidence).
-1 = no values for clinical significance at all for this variant or set of variants; used for
the "included" variants that are only in ClinVar because they are included in a
haplotype or genotype with an interpretation
NOTE: Now that the aggregate values of clinical significance give precedence to records with
assertion criteria and evidence, the values in this column may appear to be in conflict with the
value reported in ClinicalSignificance.  In other words, if a submission without assertion criteria and
evidence interpreted an allele as pathogenic, and those with assertion criteria and evidence interpreted
as benign, then ClinicalSignificance would be reported as Benign and ClinSigSimple as 1.

\item \code{get_data_package()}: get_

\item \code{get_definitions()}: get_
Add ancestor

For each term, get its ancestor at a given level
and add the ID and name of the ancestor to the ontology metadata.

\item \code{get_gencc()}: get_
Get GenCC

Get phenotype-gene evidence score from the
\href{https://thegencc.org/}{Gene Curation Coalition}.
Note that the column "submitted_as_moi_id" indicates the mechanism of action
 (e.g. "Autosomal dominant inheritance"), not specific HPO phenotypes.
Set \code{agg_by=NULL} to return raw unaggregated data.

Data downloaded from \href{https://search.thegencc.org/download}{here}.\cr
\emph{NOTE:} Due to licensing restrictions, a GenCC download does not
 include OMIM data. OMIM data can be accessed and downloaded through
 \href{https://omim.org/downloads/}{OMIM}.\cr
\emph{NOTE:} GenCC does not currently have any systematic versioning.
There for the \code{attr(obj,"version")} attribute is set to the date it was
downloaded and cached by \link{get_gencc}.

\item \code{get_gene_lengths()}: get_

\item \code{get_genes_disease()}: get_
Load disease genes

Load gene lists associated with each disease phenotype from:
\itemize{
\item{OMIM}
\item{Orphanet}
\item{DECIPHER}
}

\item \code{get_graph_colnames()}: get_
Get column names in the nodes and/or edges of a tbl_graph.

\item \code{get_medgen_maps()}: get_
Get MedGen maps.

\item \code{get_metadata_omim()}: get_

\item \code{get_metadata_orphanet()}: get_

\item \code{get_monarch()}: get_
Get Monarch

Get key datasets from the
\href{https://monarchinitiative.org/}{Monarch Initiative}
\href{https://data.monarchinitiative.org}{server}.
See
\href{https://data.monarchinitiative.org/latest/tsv/all_associations/}{here}
 for all associations data, specifically.

\item \code{get_monarch_files()}: get_
Monarch files

Find files 
\href{https://monarchinitiative.org/}{Monarch Initiative}
\href{https://data.monarchinitiative.org}{server}.

\item \code{get_monarch_kg()}: get_
Get knowledge graph: Monarch

Imports the entire Monarch knowledge graph containing >500,000 nodes 
and >10,000,000 edges across many categories 
(e.g. Disease, Phenotypes, Cell Types, etc.).

Option 1: Use the \href{https://api.monarchinitiative.org/api/}{biolink API}
 to efficiently extract specific subset of data
from the Monarch server.
Option 2: Import the entire knowledge graph from the
\href{https://data.monarchinitiative.org/monarch-kg/latest/}{Monarch server}.

\item \code{get_monarch_models()}: get_
Get Monarch models

Get disease-to-model mappings for multiple model species.
Additionally maps mondo IDs to OMIM and Orphanet IDs.  
NOTE, adding additional \code{maps} 
will drastically reduce the number of results.

\item \code{get_mondo_maps()}: get_
Get Mondo ID maps

Get mappings between Mondo IDs and IDs in other databases/ontologies.
All mappings stored on the official
\href{https://github.com/monarch-initiative/mondo/tree/master/src/ontology/mappings}{
Mondo GitHub}.

\item \code{get_mondo_maps_files()}: get_

\item \code{get_ols_options()}: get_
Get a complete up=to-date list of ontologies available via the
\href{https://www.ebi.ac.uk/ols4}{EBML-EBI Ontology Lookup Service} API.

\item \code{get_ontology()}: get_ontology
Get ontology

Import an up-to-date ontology directly from from the creators or via the
\href{https://www.ebi.ac.uk/ols4}{EBML-EBI Ontology Lookup Service} API.

\item \code{get_ontology_dict()}: get_

\item \code{get_ontology_levels()}: get_
Get ontology level for ontology terms

For a given set of HPO terms, get their level
within the hierarchically organised ontology.
Ontology level can be computed either absolute mode (\code{absolute=TRUE})
where the entire ontology is considered when assigning levels, or
relative mode (\code{absolute=FALSE}) where only a subset of the ontology
that is connected to a given term is considered when assigning levels.
Relative mode can be helpful when trying to make plot where nodes are
scaled to the ontology level.

\item \code{get_pli()}: get_
Get pLI

Get gene-level \href{https://gnomad.broadinstitute.org/faq#what-is-pli}{
pLI} scores for all canonical and non-canonical protein-coding gene
transcripts.
NOTE: The MANE Select set consists of one transcript at each protein-coding
locus across the genome that is representative of biology at that locus.
NOTE: Mapping genes with \link[orthogene]{map_genes} only reduces the number
of mapped genes compared to the provided "gene" column.

\item \code{get_prevalence()}: get_
Get prevalence

Get epidemiological disease and phenotype prevalence data.

\item \code{get_ttd()}: get_

\item \code{get_upheno()}: get_ 
Get uPheno

Get data from the \href{https://github.com/obophenotype/upheno}{
Unified Phenotype Ontology (uPheno)}.

\item \code{get_version()}: get_
Get version

For a given ontology, extract the precise version of the Release that the 
data object was built from. For Human Phenotype Ontology specifically,
 all Releases can be found at the official
\href{https://github.com/obophenotype/human-phenotype-ontology/releases}{
HPO GitHub Releases page}.

}}
\examples{
\dontrun{
am <- get_alphamissense()
}
ont <- get_ontology("hp", terms=10)
def <- get_definitions(ont)
d <- get_gencc()
genes <- get_genes_disease()
dat <- get_monarch(maps=list(c("gene","disease")))
files <- get_monarch_files() 
\dontrun{
g <- get_monarch_kg(save_dir=tempdir(), nrows=100)
}
models <- get_monarch_models()
map <- get_mondo_maps("default") 
mondo <- get_ontology(name="mondo")
\dontrun{
  hp <- get_ontology(name="hp")
  upheno <- get_ontology(name="upheno")
}
ont <- get_ontology("hp", terms=10)
dict <- get_ontology_dict(ont)
ont <- get_ontology("hp")
terms <- ont@terms[1:10]
lvls <- get_ontology_levels(ont, terms = terms)
lvls_rel <- get_ontology_levels(ont, terms = terms, absolute=FALSE)
\dontrun{
pli <- get_pli()
}
\dontrun{
get_prevalence()
}
ttd <- get_ttd()
upheno <- get_upheno()
obj <- get_ontology("hp")
get_version(obj=obj)
}
\concept{get_}
